{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR Assignment 2022-23\n",
    "\n",
    "This notebook has been provided as a template to get you started on the assignment.  Feel free to use it for your development, or do your development directly in Python.\n",
    "\n",
    "You can find a full description of the assignment [here](http://www.inf.ed.ac.uk/teaching/courses/asr/2022-23/coursework.pdf).\n",
    "\n",
    "You are provided with two Python modules `observation_model.py` and `wer.py`.  The first was described in [Lab 3](https://github.com/ZhaoZeyu1995/asr_labs/blob/master/asr_lab3_4.ipynb).  The second can be used to compute the number of substitution, deletion and insertion errors between ASR output and a reference text.\n",
    "\n",
    "It can be used as follows:\n",
    "\n",
    "```python\n",
    "import wer\n",
    "\n",
    "my_refence = 'A B C'\n",
    "my_output = 'A C C D'\n",
    "\n",
    "wer.compute_alignment_errors(my_reference, my_output)\n",
    "```\n",
    "\n",
    "This produces a tuple $(s,d,i)$ giving counts of substitution,\n",
    "deletion and insertion errors respectively - in this example (1, 0, 1).  The function accepts either two strings, as in the example above, or two lists.  Matching is case sensitive.\n",
    "\n",
    "## Template code\n",
    "\n",
    "Assuming that you have already made a function to generate an WFST, `create_wfst()` and a decoder class, `MyViterbiDecoder`, you can perform recognition on all the audio files as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import observation_model\n",
    "import math\n",
    "import openfst_python as fst\n",
    "\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import wer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "\n",
    "        \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []   # stores likelihood along best path reaching state j\n",
    "        self.B = []   # stores identity of best previous state reaching state j\n",
    "        self.W = []   # stores output labels sequence along arc reaching j - this removes need for \n",
    "                      # extra code to read the output sequence along the best path\n",
    "        \n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "            self.B.append([-1]*self.f.num_states())\n",
    "            self.W.append([[] for i in range(self.f.num_states())])  #  multiplying the empty list doesn't make multiple\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.V[0][self.f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)        \n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(self.f.states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if self.V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in self.f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if self.V[t][j] > self.V[t][i] + float(arc.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.V[t][j] = self.V[t][i] + float(arc.weight)\n",
    "                        \n",
    "                        # save backtrace information.  In the case of an epsilon transition, \n",
    "                        # we save the identity of the best state at t-1.  This means we may not\n",
    "                        # be able to fully recover the best path, but to do otherwise would\n",
    "                        # require a more complicated way of storing backtrace information\n",
    "                        self.B[t][j] = self.B[t][i] \n",
    "                        \n",
    "                        # and save the output labels encountered - this is a list, because\n",
    "                        # there could be multiple output labels (in the case of <eps> arcs)\n",
    "                        if arc.olabel != 0:\n",
    "                            self.W[t][j] = self.W[t][i] + [arc.olabel]\n",
    "                        else:\n",
    "                            self.W[t][j] = self.W[t][i]\n",
    "                        \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "          \n",
    "        for i in self.f.states():\n",
    "            \n",
    "            if not self.V[t-1][i] == self.NLL_ZERO:   # no point in propagating states with zero probability\n",
    "                \n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0: # <eps> transitions don't emit an observation\n",
    "                        j = arc.nextstate\n",
    "                        tp = float(arc.weight)  # transition prob\n",
    "                        ep = -self.om.log_observation_probability(self.f.input_symbols().find(arc.ilabel), t)  # emission negative log prob\n",
    "                        prob = tp + ep + self.V[t-1][i] # they're logs\n",
    "                        if prob < self.V[t][j]:\n",
    "                            self.V[t][j] = prob\n",
    "                            self.B[t][j] = i\n",
    "                            \n",
    "                            # store the output labels encountered too\n",
    "                            if arc.olabel !=0:\n",
    "                                self.W[t][j] = [arc.olabel]\n",
    "                            else:\n",
    "                                self.W[t][j] = []\n",
    "                            \n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \"\"\" this incorporates the probability of terminating at each state\n",
    "        \"\"\"\n",
    "        \n",
    "        for state in self.f.states():\n",
    "            final_weight = float(self.f.final(state))\n",
    "            if self.V[-1][state] != self.NLL_ZERO:\n",
    "                if final_weight == math.inf:\n",
    "                    self.V[-1][state] = self.NLL_ZERO  # effectively says that we can't end in this state\n",
    "                else:\n",
    "                    self.V[-1][state] += final_weight\n",
    "                    \n",
    "        # get a list of all states where there was a path ending with non-zero probability\n",
    "        finished = [x for x in self.V[-1] if x < self.NLL_ZERO]\n",
    "        if not finished:  # if empty\n",
    "            print(\"No path got to the end of the observations.\")\n",
    "        \n",
    "        \n",
    "    def decode(self):\n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            self.traverse_epsilon_arcs(t)\n",
    "            t += 1\n",
    "        self.finalise_decoding()\n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        best_final_state = self.V[-1].index(min(self.V[-1])) # argmin\n",
    "        best_state_sequence = [best_final_state]\n",
    "        best_out_sequence = []\n",
    "        \n",
    "        t = self.om.observation_length()   # ie T\n",
    "        j = best_final_state\n",
    "        \n",
    "        while t >= 0:\n",
    "            i = self.B[t][j]\n",
    "            best_state_sequence.append(i)\n",
    "            best_out_sequence = self.W[t][j] + best_out_sequence  # computer scientists might like\n",
    "                                                                                # to make this more efficient!\n",
    "\n",
    "            # continue the backtrace at state i, time t-1\n",
    "            j = i  \n",
    "            t-=1\n",
    "            \n",
    "        best_state_sequence.reverse()\n",
    "        \n",
    "        # convert the best output sequence from FST integer labels into strings\n",
    "        best_out_sequence = ' '.join([ self.f.output_symbols().find(label) for label in best_out_sequence])\n",
    "        \n",
    "        return (best_state_sequence, best_out_sequence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wfst(f):\n",
    "    f.draw('tmp.dot', portrait=True)\n",
    "    check_call(['dot','-Tpng','-Gdpi=500','tmp.dot','-o','tmp.png'])\n",
    "    Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lexicon(lex_file):\n",
    "    \"\"\"\n",
    "    Parse the lexicon file and return it in dictionary form.\n",
    "    \n",
    "    Args:\n",
    "        lex_file (str): filename of lexicon file with structure '<word> <phone1> <phone2>...'\n",
    "                        eg. peppers p eh p er z\n",
    "\n",
    "    Returns:\n",
    "        lex (dict): dictionary mapping words to list of phones\n",
    "    \"\"\"\n",
    "    \n",
    "    lex = {}  # create a dictionary for the lexicon entries (this could be a problem with larger lexica)\n",
    "    with open(lex_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.split()  # split at each space\n",
    "            if line[0] in lex.keys():\n",
    "                lex[line[0] + \"_\"] = line[1:] \n",
    "            else:\n",
    "                lex[line[0]] = line[1:]  # first field the word, the rest is the phones\n",
    "    return lex\n",
    "\n",
    "def generate_symbol_tables(lexicon, n=3):\n",
    "    '''\n",
    "    Return word, phone and state symbol tables based on the supplied lexicon\n",
    "        \n",
    "    Args:\n",
    "        lexicon (dict): lexicon to use, created from the parse_lexicon() function\n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        word_table (fst.SymbolTable): table of words\n",
    "        phone_table (fst.SymbolTable): table of phones\n",
    "        state_table (fst.SymbolTable): table of HMM phone-state IDs\n",
    "    '''\n",
    "    \n",
    "    state_table = fst.SymbolTable()\n",
    "    phone_table = fst.SymbolTable()\n",
    "    word_table = fst.SymbolTable()\n",
    "    \n",
    "    # add empty <eps> symbol to all tables\n",
    "    state_table.add_symbol('<eps>')\n",
    "    phone_table.add_symbol('<eps>')\n",
    "    word_table.add_symbol('<eps>')\n",
    "    \n",
    "    for word, phones  in lexicon.items():\n",
    "        \n",
    "        word_table.add_symbol(word)\n",
    "        \n",
    "        for p in phones: # for each phone\n",
    "            \n",
    "            phone_table.add_symbol(p)\n",
    "            for i in range(1,n+1): # for each state 1 to n\n",
    "                state_table.add_symbol('{}_{}'.format(p, i))\n",
    "            \n",
    "    return word_table, phone_table, state_table\n",
    "\n",
    "\n",
    "# call these two functions\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "\n",
    "def generate_phone_wfst(f, start_state, phone, n, loop_w, next_w ):\n",
    "    \"\"\"\n",
    "    Generate a WFST representating an n-state left-to-right phone HMM\n",
    "    \n",
    "    Args:\n",
    "        f (fst.Fst()): an FST object, assumed to exist already\n",
    "        start_state (int): the index of the first state, assmed to exist already\n",
    "        phone (str): the phone label \n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        the final state of the FST\n",
    "    \"\"\"\n",
    "    \n",
    "    current_state = start_state\n",
    "    sl_weight = fst.Weight('log', -math.log(loop_w))  # weight for self-loop\n",
    "    next_weight = fst.Weight('log', -math.log(next_w)) # weight to next state\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        in_label = state_table.find('{}_{}'.format(phone, i))\n",
    "        \n",
    "        # self-loop back to current state\n",
    "        f.add_arc(current_state, fst.Arc(in_label, 0, sl_weight, current_state))\n",
    "        \n",
    "        # transition to next state\n",
    "        \n",
    "        # we want to output the phone label on the final state\n",
    "        # note: if outputting words instead this code should be modified\n",
    "        if i == n:\n",
    "            out_label = phone_table.find(phone)\n",
    "        else:\n",
    "            out_label = 0   # output empty <eps> label\n",
    "            \n",
    "        next_state = f.add_state()\n",
    "        f.add_arc(current_state, fst.Arc(in_label, 0, next_weight, next_state))    # changed to 0 ! \n",
    "       \n",
    "        current_state = next_state\n",
    "        \n",
    "    return current_state\n",
    "\n",
    "def generate_word_wfst(word):\n",
    "    \"\"\" Generate a WFST for any word in the lexicon, composed of 3-state phone WFSTs.\n",
    "        This will currently output word labels.  \n",
    "        Exercise: could you modify this function and the one above to output a single phone label instead?\n",
    "    \n",
    "    Args:\n",
    "        word (str): the word to generate\n",
    "        \n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    f = fst.Fst('log')\n",
    "    \n",
    "    # create the start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    current_state = start_state\n",
    "    \n",
    "    # iterate over all the phones in the word\n",
    "    for (i,phone) in enumerate(lex[word]):   # will raise an exception if word is not in the lexicon\n",
    "        \n",
    "        current_state = generate_phone_wfst(f, current_state, phone, 3)\n",
    "    \n",
    "        if i == len(lex[word]) - 1:\n",
    "            next_state = f.add_state()\n",
    "            f.add_arc(current_state, fst.Arc(in_label, word_table.find(word), certain_weight, current_state))\n",
    "            \n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "        \n",
    "    f.set_final(current_state)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def generate_word_sequence_recognition_wfst(n, probs, loop_w, next_w):\n",
    "    \"\"\" generate a HMM to recognise any single word sequence for words in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "\n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    \n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    #reduced_weight = fst.Weight('log', -math.log(1/(5*len(lex))))\n",
    "    next_weight = fst.Weight('log', -math.log(0.1))\n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    #f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(0.3)), start_state))\n",
    "    \n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "\n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(probs[word])), current_state))\n",
    "        \n",
    "        for (i, phone) in enumerate(phones): \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n, loop_w , next_w)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "            if i == len(lex[word]) - 1:\n",
    "\n",
    "                next_state = f.add_state()\n",
    "                f.add_arc(current_state, fst.Arc(0, word_table.find(word.replace(\"_\", \"\")), certain_weight, next_state))\n",
    "                current_state= next_state\n",
    "                \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, next_weight, start_state))\n",
    "        \n",
    "    return f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wfst(n, state_table, phone_table, word_probabilities, loop_w = 0.3, next_w = 0.7):\n",
    "    # word probabilities: a dictionary, to adjust weights. \n",
    "    f = generate_word_sequence_recognition_wfst(n, word_probabilities, loop_w, next_w)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(word_table)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_dict = {}\n",
    "for word, _ in lex.items():\n",
    "    even_dict[word] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 154 µs, sys: 74 µs, total: 228 µs\n",
      "Wall time: 232 µs\n",
      "the of pickled piper the of peter the\n",
      "a pickled piper of peter\n",
      "(1, 0, 3) 5\n",
      "CPU times: user 163 µs, sys: 52 µs, total: 215 µs\n",
      "Wall time: 220 µs\n",
      "the where's peter the\n",
      "where's peter\n",
      "(0, 0, 2) 2\n",
      "CPU times: user 247 µs, sys: 55 µs, total: 302 µs\n",
      "Wall time: 308 µs\n",
      "CPU times: user 389 µs, sys: 67 µs, total: 456 µs\n",
      "Wall time: 467 µs\n",
      "CPU times: user 198 µs, sys: 27 µs, total: 225 µs\n",
      "Wall time: 230 µs\n",
      "CPU times: user 344 µs, sys: 37 µs, total: 381 µs\n",
      "Wall time: 386 µs\n",
      "CPU times: user 227 µs, sys: 21 µs, total: 248 µs\n",
      "Wall time: 252 µs\n",
      "CPU times: user 363 µs, sys: 29 µs, total: 392 µs\n",
      "Wall time: 397 µs\n",
      "CPU times: user 266 µs, sys: 18 µs, total: 284 µs\n",
      "Wall time: 288 µs\n",
      "2080 318 2434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "utterance_c = 0\n",
    "word_c = 0\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst(3, state_table, phone_table, even_dict)\n",
    "errors_sum = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "        #if utterance_c < 6:                                                            # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "        decoder.decode()\n",
    "        if utterance_c < 10:\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace()\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 3:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count) # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        word_c += word_count\n",
    "print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 242 µs, sys: 0 ns, total: 242 µs\n",
      "Wall time: 247 µs\n",
      "the of pickled piper the of peter the\n",
      "a pickled piper of peter\n",
      "(1, 0, 3) 5\n",
      "CPU times: user 170 µs, sys: 0 ns, total: 170 µs\n",
      "Wall time: 174 µs\n",
      "the where's peter the\n",
      "where's peter\n",
      "(0, 0, 2) 2\n",
      "CPU times: user 200 µs, sys: 0 ns, total: 200 µs\n",
      "Wall time: 204 µs\n",
      "CPU times: user 198 µs, sys: 1 µs, total: 199 µs\n",
      "Wall time: 203 µs\n",
      "CPU times: user 266 µs, sys: 1 µs, total: 267 µs\n",
      "Wall time: 273 µs\n",
      "CPU times: user 395 µs, sys: 2 µs, total: 397 µs\n",
      "Wall time: 402 µs\n",
      "CPU times: user 239 µs, sys: 1 µs, total: 240 µs\n",
      "Wall time: 244 µs\n",
      "CPU times: user 305 µs, sys: 1 µs, total: 306 µs\n",
      "Wall time: 311 µs\n",
      "CPU times: user 284 µs, sys: 2 µs, total: 286 µs\n",
      "Wall time: 290 µs\n",
      "1725 318 2434\n"
     ]
    }
   ],
   "source": [
    "utterance_c = 0\n",
    "word_c = 0\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst(3, state_table, phone_table, even_dict, 0.7, 0.3)\n",
    "errors_sum = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                          # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "        decoder.decode()\n",
    "        if utterance_c < 10:\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace()\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 3:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count) # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        word_c += word_count\n",
    "print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 283 µs, sys: 2 µs, total: 285 µs\n",
      "Wall time: 289 µs\n",
      "the of pickled piper the of peter the\n",
      "a pickled piper of peter\n",
      "(1, 0, 3) 5\n",
      "CPU times: user 167 µs, sys: 0 ns, total: 167 µs\n",
      "Wall time: 172 µs\n",
      "the where's peter the\n",
      "where's peter\n",
      "(0, 0, 2) 2\n",
      "CPU times: user 214 µs, sys: 1 µs, total: 215 µs\n",
      "Wall time: 219 µs\n",
      "CPU times: user 208 µs, sys: 0 ns, total: 208 µs\n",
      "Wall time: 212 µs\n",
      "CPU times: user 248 µs, sys: 1e+03 ns, total: 249 µs\n",
      "Wall time: 253 µs\n",
      "CPU times: user 398 µs, sys: 2 µs, total: 400 µs\n",
      "Wall time: 404 µs\n",
      "CPU times: user 273 µs, sys: 1e+03 ns, total: 274 µs\n",
      "Wall time: 280 µs\n",
      "CPU times: user 319 µs, sys: 1e+03 ns, total: 320 µs\n",
      "Wall time: 325 µs\n",
      "CPU times: user 297 µs, sys: 1e+03 ns, total: 298 µs\n",
      "Wall time: 302 µs\n",
      "1855 318 2434\n"
     ]
    }
   ],
   "source": [
    "utterance_c = 0\n",
    "word_c = 0\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst(3, state_table, phone_table, even_dict, 0.5, 0.5)\n",
    "errors_sum = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                    # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "        decoder.decode()\n",
    "        if utterance_c < 10:\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace()\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 3:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count) # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        word_c += word_count\n",
    "print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 269 µs, sys: 1e+03 ns, total: 270 µs\n",
      "Wall time: 276 µs\n",
      "the of pickled piper of peter the\n",
      "a pickled piper of peter\n",
      "(1, 0, 2) 5\n",
      "CPU times: user 203 µs, sys: 1e+03 ns, total: 204 µs\n",
      "Wall time: 208 µs\n",
      "the where's peter the\n",
      "where's peter\n",
      "(0, 0, 2) 2\n",
      "CPU times: user 238 µs, sys: 1 µs, total: 239 µs\n",
      "Wall time: 243 µs\n",
      "CPU times: user 206 µs, sys: 0 ns, total: 206 µs\n",
      "Wall time: 210 µs\n",
      "CPU times: user 256 µs, sys: 0 ns, total: 256 µs\n",
      "Wall time: 261 µs\n",
      "CPU times: user 417 µs, sys: 2 µs, total: 419 µs\n",
      "Wall time: 423 µs\n",
      "CPU times: user 270 µs, sys: 1 µs, total: 271 µs\n",
      "Wall time: 276 µs\n",
      "CPU times: user 314 µs, sys: 1e+03 ns, total: 315 µs\n",
      "Wall time: 319 µs\n",
      "CPU times: user 286 µs, sys: 0 ns, total: 286 µs\n",
      "Wall time: 290 µs\n",
      "1608 318 2434\n"
     ]
    }
   ],
   "source": [
    "utterance_c = 0\n",
    "word_c = 0\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst(3, state_table, phone_table, even_dict, 0.9, 0.1)\n",
    "errors_sum = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                    # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "        decoder.decode()\n",
    "        if utterance_c < 10:\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace()\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 3:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count) # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        word_c += word_count\n",
    "print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 299 µs, sys: 1 µs, total: 300 µs\n",
      "Wall time: 304 µs\n",
      "picked the of pickled piper the a of peter a picked the the\n",
      "a pickled piper of peter\n",
      "(1, 0, 8) 5\n",
      "CPU times: user 207 µs, sys: 1e+03 ns, total: 208 µs\n",
      "Wall time: 211 µs\n",
      "picked the where's peter picked the\n",
      "where's peter\n",
      "(0, 0, 4) 2\n",
      "CPU times: user 277 µs, sys: 0 ns, total: 277 µs\n",
      "Wall time: 281 µs\n",
      "CPU times: user 213 µs, sys: 0 ns, total: 213 µs\n",
      "Wall time: 216 µs\n",
      "CPU times: user 220 µs, sys: 0 ns, total: 220 µs\n",
      "Wall time: 225 µs\n",
      "CPU times: user 432 µs, sys: 1e+03 ns, total: 433 µs\n",
      "Wall time: 438 µs\n",
      "CPU times: user 253 µs, sys: 1e+03 ns, total: 254 µs\n",
      "Wall time: 258 µs\n",
      "CPU times: user 517 µs, sys: 1e+03 ns, total: 518 µs\n",
      "Wall time: 524 µs\n",
      "CPU times: user 408 µs, sys: 2 µs, total: 410 µs\n",
      "Wall time: 414 µs\n",
      "3028 318 2434\n"
     ]
    }
   ],
   "source": [
    "utterance_c = 0\n",
    "word_c = 0\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst(3, state_table, phone_table, even_dict, 0.1, 0.9)\n",
    "errors_sum = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                    # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "        decoder.decode()\n",
    "        if utterance_c < 10:\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace()\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 3:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count) # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        word_c += word_count\n",
    "print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of states for assesing memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(f.states()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1\n",
    "for word, phones in lex.items():\n",
    "        a += 3*len(phones) + 2\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wfst with unigram probabilities based on counts, instead of even probabilities for all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.05834018077239113,\n",
       " 'of': 0.10230073952341824,\n",
       " 'peck': 0.11133935907970419,\n",
       " 'peppers': 0.13475760065735415,\n",
       " 'peter': 0.12900575184880855,\n",
       " 'picked': 0.11298274445357437,\n",
       " 'pickled': 0.11750205423171733,\n",
       " 'piper': 0.11503697617091208,\n",
       " 'the': 0.06409202958093672,\n",
       " \"where's\": 0.05464256368118324,\n",
       " 'SUM': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = {}\n",
    "for word in lex.keys():\n",
    "    c[word] = 0\n",
    "c[\"SUM\"] = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):\n",
    "    transcript=read_transcription(wav_file)\n",
    "    for word in lex.keys():\n",
    "        count = transcript.count(word)\n",
    "        c[word] += count\n",
    "        c[\"SUM\"] += count\n",
    "        \n",
    "        \n",
    "unigram_probs = {}\n",
    "for w, count in c.items():\n",
    "    if \"_\" not in w:\n",
    "        unigram_probs[w] = count /c[\"SUM\"]\n",
    "        \n",
    "unigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_sequence_recognition_wfst_unigram(n, probs):\n",
    "    \"\"\" generate a HMM to recognise any single word sequence for words in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "\n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    \n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    #reduced_weight = fst.Weight('log', -math.log(1/(5*len(lex))))\n",
    "    next_weight = fst.Weight('log', -math.log(0.05))\n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    #f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(0.3)), start_state))\n",
    "    \n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "\n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(probs[w])), current_state))\n",
    "        \n",
    "        for (i, phone) in enumerate(phones): \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n, 0.9, 0.1)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "            if i == len(lex[word]) - 1:\n",
    "\n",
    "                next_state = f.add_state()\n",
    "                f.add_arc(current_state, fst.Arc(0, word_table.find(word.replace(\"_\", \"\")), certain_weight, next_state))\n",
    "                current_state= next_state\n",
    "                \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, next_weight, start_state))\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "def create_wfst_unigram(n, state_table, phone_table, word_probabilities):\n",
    "    # word probabilities: a dictionary, to adjust weights. \n",
    "    f = generate_word_sequence_recognition_wfst_unigram(n, word_probabilities)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(word_table)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 148 µs, sys: 88 µs, total: 236 µs\n",
      "Wall time: 239 µs\n",
      "the of pickled piper of peter the\n",
      "a pickled piper of peter\n",
      "(1, 0, 2) 5\n",
      "CPU times: user 171 µs, sys: 0 ns, total: 171 µs\n",
      "Wall time: 174 µs\n",
      "the where's peter the\n",
      "where's peter\n",
      "(0, 0, 2) 2\n",
      "CPU times: user 196 µs, sys: 0 ns, total: 196 µs\n",
      "Wall time: 199 µs\n",
      "CPU times: user 152 µs, sys: 36 µs, total: 188 µs\n",
      "Wall time: 193 µs\n",
      "CPU times: user 178 µs, sys: 35 µs, total: 213 µs\n",
      "Wall time: 217 µs\n",
      "CPU times: user 372 µs, sys: 55 µs, total: 427 µs\n",
      "Wall time: 432 µs\n",
      "CPU times: user 224 µs, sys: 28 µs, total: 252 µs\n",
      "Wall time: 257 µs\n",
      "CPU times: user 281 µs, sys: 31 µs, total: 312 µs\n",
      "Wall time: 317 µs\n",
      "CPU times: user 276 µs, sys: 27 µs, total: 303 µs\n",
      "Wall time: 308 µs\n",
      "1628 318 2434\n"
     ]
    }
   ],
   "source": [
    "utterance_c = 0\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst_unigram(3, state_table, phone_table, unigram_probs)\n",
    "errors_sum = 0\n",
    "word_c = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "                                                                   # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        decoder.decode()\n",
    "        if utterance_c < 10:\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace() \n",
    "        \n",
    "        transcription = read_transcription(wav_file)                                    \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "    \n",
    "        if utterance_c < 3:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count) # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        word_c += word_count\n",
    "\n",
    "print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding silence states at the start and between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_table.add_symbol(\"sil_1\")\n",
    "state_table.add_symbol(\"sil_2\")\n",
    "state_table.add_symbol(\"sil_3\")\n",
    "state_table.add_symbol(\"sil_4\")\n",
    "state_table.add_symbol(\"sil_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sil_wfst(n, word_probabilities):\n",
    "    \"\"\" generate a HMM to recognise any single word sequence for words in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "\n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    \n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    #reduced_weight = fst.Weight('log', -math.log(1/(5*len(lex))))\n",
    "    next_weight = fst.Weight('log', -math.log(0.1))\n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    first_silent = f.add_state()\n",
    "    last_silent = f.add_state()\n",
    "    f.set_final(last_silent)\n",
    "    \n",
    "    \n",
    "    f.add_arc(start_state, fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', -math.log(0.1)),first_silent))\n",
    "    f.add_arc(last_silent, fst.Arc(0, 0, fst.Weight('log', -math.log(1)),start_state))\n",
    "    curr_state = first_silent\n",
    "    for i in range(2, 5):\n",
    "        nxt_state = f.add_state()\n",
    "        f.add_arc(nxt_state, fst.Arc(state_table.find((\"sil_\" + str(i))), 0, \n",
    "                                      fst.Weight('log', -math.log(0.9)),nxt_state))\n",
    "        f.add_arc(curr_state, fst.Arc(state_table.find((\"sil_\" + str(i))), 0, \n",
    "                                      fst.Weight('log', -math.log(0.1)),nxt_state))\n",
    "        f.add_arc(first_silent, fst.Arc(state_table.find((\"sil_\" + str(i))), 0, \n",
    "                                        fst.Weight('log', -math.log(0.1)),nxt_state))\n",
    "        f.add_arc(nxt_state, fst.Arc(state_table.find((\"sil_5\" )), 0, \n",
    "                                      fst.Weight('log', -math.log(0.1)),last_silent))\n",
    "        curr_state = nxt_state\n",
    "    \n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "        \n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(word_probabilities[word])), current_state))\n",
    "        \n",
    "        for (i, phone) in enumerate(phones): \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n, 0.9, 0.1)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "            if i == len(lex[word]) - 1:\n",
    "\n",
    "                next_state = f.add_state()\n",
    "                f.add_arc(current_state, fst.Arc(0, word_table.find(word.replace(\"_\", \"\")), certain_weight, next_state))\n",
    "                current_state= next_state\n",
    "                \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, next_weight, start_state))\n",
    "        \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44363/510309964.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_wfst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "show_wfst(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.29 s, sys: 38.5 ms, total: 2.33 s\n",
      "Wall time: 2.29 s\n",
      "CPU times: user 119 µs, sys: 84 µs, total: 203 µs\n",
      "Wall time: 206 µs\n",
      "of pickled piper of peter\n",
      "a pickled piper of peter\n",
      "(1, 0, 0) 5\n",
      "CPU times: user 1.52 s, sys: 0 ns, total: 1.52 s\n",
      "Wall time: 1.53 s\n",
      "CPU times: user 145 µs, sys: 0 ns, total: 145 µs\n",
      "Wall time: 148 µs\n",
      "where's peter\n",
      "where's peter\n",
      "(0, 0, 0) 2\n",
      "CPU times: user 1.86 s, sys: 2.1 ms, total: 1.86 s\n",
      "Wall time: 1.86 s\n",
      "CPU times: user 128 µs, sys: 45 µs, total: 173 µs\n",
      "Wall time: 178 µs\n",
      "peter picked peck\n",
      "peter picked a peck\n",
      "(0, 1, 0) 4\n",
      "CPU times: user 1.93 s, sys: 0 ns, total: 1.93 s\n",
      "Wall time: 1.93 s\n",
      "CPU times: user 173 µs, sys: 0 ns, total: 173 µs\n",
      "Wall time: 177 µs\n",
      "CPU times: user 2.17 s, sys: 0 ns, total: 2.17 s\n",
      "Wall time: 2.17 s\n",
      "CPU times: user 213 µs, sys: 0 ns, total: 213 µs\n",
      "Wall time: 217 µs\n",
      "CPU times: user 3.97 s, sys: 11.3 ms, total: 3.98 s\n",
      "Wall time: 3.98 s\n",
      "CPU times: user 389 µs, sys: 0 ns, total: 389 µs\n",
      "Wall time: 392 µs\n",
      "CPU times: user 2.52 s, sys: 0 ns, total: 2.52 s\n",
      "Wall time: 2.52 s\n",
      "CPU times: user 249 µs, sys: 0 ns, total: 249 µs\n",
      "Wall time: 253 µs\n",
      "CPU times: user 2.98 s, sys: 0 ns, total: 2.98 s\n",
      "Wall time: 2.98 s\n",
      "CPU times: user 344 µs, sys: 0 ns, total: 344 µs\n",
      "Wall time: 347 µs\n",
      "CPU times: user 3.05 s, sys: 11.7 ms, total: 3.07 s\n",
      "Wall time: 3.07 s\n",
      "CPU times: user 309 µs, sys: 0 ns, total: 309 µs\n",
      "Wall time: 314 µs\n"
     ]
    }
   ],
   "source": [
    "s = generate_sil_wfst(3, even_dict)\n",
    "s.set_input_symbols(state_table)\n",
    "s.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterances = 0\n",
    "words_no = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "        #if utterances < 10:                                                                       # audio files\n",
    "        utterances += 1\n",
    "        decoder = MyViterbiDecoder(s, wav_file)\n",
    "    \n",
    "        if utterances < 10:\n",
    "            %time decoder.decode()\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace()\n",
    "            decoder.decode()\n",
    "            \n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "    \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "    \n",
    "        if utterances < 4:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_no += word_count\n",
    "print(errors_sum, utterances, words_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name, pruning_threshold = 500):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "        self.threshold = pruning_threshold\n",
    "\n",
    "        \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []   # stores likelihood along best path reaching state j\n",
    "        self.B = []   # stores identity of best previous state reaching state j\n",
    "        self.W = []   # stores output labels sequence along arc reaching j - this removes need for \n",
    "                      # extra code to read the output sequence along the best path\n",
    "        \n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "            self.B.append([-1]*self.f.num_states())\n",
    "            self.W.append([[] for i in range(self.f.num_states())])  #  multiplying the empty list doesn't make multiple\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.V[0][self.f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)        \n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(self.f.states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if self.V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in self.f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if self.V[t][j] > self.V[t][i] + float(arc.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.V[t][j] = self.V[t][i] + float(arc.weight)\n",
    "                        \n",
    "                        # save backtrace information.  In the case of an epsilon transition, \n",
    "                        # we save the identity of the best state at t-1.  This means we may not\n",
    "                        # be able to fully recover the best path, but to do otherwise would\n",
    "                        # require a more complicated way of storing backtrace information\n",
    "                        self.B[t][j] = self.B[t][i] \n",
    "                        \n",
    "                        # and save the output labels encountered - this is a list, because\n",
    "                        # there could be multiple output labels (in the case of <eps> arcs)\n",
    "                        if arc.olabel != 0:\n",
    "                            self.W[t][j] = self.W[t][i] + [arc.olabel]\n",
    "                        else:\n",
    "                            self.W[t][j] = self.W[t][i]\n",
    "                        \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "        #find the best V[t-1]\n",
    "        best = max(0.1, min(self.V[t-1]))\n",
    "        for i in self.f.states():\n",
    "            \n",
    "            #if not self.V[t-1][i] == self.NLL_ZERO:   # no point in propagating states with zero probability\n",
    "            if self.V[t-1][i] < best* self.threshold:   # bigger value means lower probability ! \n",
    "                #print(self.V[t-1][i])\n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0: # <eps> transitions don't emit an observation\n",
    "                        j = arc.nextstate\n",
    "                        tp = float(arc.weight)  # transition prob\n",
    "                        ep = -self.om.log_observation_probability(self.f.input_symbols().find(arc.ilabel), t)  # emission negative log prob\n",
    "                        prob = tp + ep + self.V[t-1][i] # they're logs\n",
    "                        if prob < self.V[t][j]:\n",
    "                            self.V[t][j] = prob\n",
    "                            self.B[t][j] = i\n",
    "                            \n",
    "                            # store the output labels encountered too\n",
    "                            if arc.olabel !=0:\n",
    "                                self.W[t][j] = [arc.olabel]\n",
    "                            else:\n",
    "                                self.W[t][j] = []\n",
    "                            \n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \"\"\" this incorporates the probability of terminating at each state\n",
    "        \"\"\"\n",
    "        \n",
    "        for state in self.f.states():\n",
    "            final_weight = float(self.f.final(state))\n",
    "            if self.V[-1][state] != self.NLL_ZERO:\n",
    "                if final_weight == math.inf:\n",
    "                    self.V[-1][state] = self.NLL_ZERO  # effectively says that we can't end in this state\n",
    "                else:\n",
    "                    self.V[-1][state] += final_weight\n",
    "                    \n",
    "        # get a list of all states where there was a path ending with non-zero probability\n",
    "        finished = [x for x in self.V[-1] if x < self.NLL_ZERO]\n",
    "        if not finished:  # if empty\n",
    "            print(\"No path got to the end of the observations.\")\n",
    "        \n",
    "        \n",
    "    def decode(self):\n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            self.traverse_epsilon_arcs(t)\n",
    "            t += 1\n",
    "        self.finalise_decoding()\n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        best_final_state = self.V[-1].index(min(self.V[-1])) # argmin\n",
    "        best_state_sequence = [best_final_state]\n",
    "        best_out_sequence = []\n",
    "        \n",
    "        t = self.om.observation_length()   # ie T\n",
    "        j = best_final_state\n",
    "        \n",
    "        while t >= 0:\n",
    "            i = self.B[t][j]\n",
    "            best_state_sequence.append(i)\n",
    "            best_out_sequence = self.W[t][j] + best_out_sequence  # computer scientists might like\n",
    "                                                                                # to make this more efficient!\n",
    "\n",
    "            # continue the backtrace at state i, time t-1\n",
    "            j = i  \n",
    "            t-=1\n",
    "            \n",
    "        best_state_sequence.reverse()\n",
    "        \n",
    "        # convert the best output sequence from FST integer labels into strings\n",
    "        best_out_sequence = ' '.join([ self.f.output_symbols().find(label) for label in best_out_sequence])\n",
    "        \n",
    "        return (best_state_sequence, best_out_sequence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict)\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =25)\n",
    "    \n",
    "        %time decoder.decode()\n",
    "        time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict)\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =40)\n",
    "    \n",
    "        if utterance_c < 10:\n",
    "            %time decoder.decode()\n",
    "        else:\n",
    "                decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
