{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR Assignment 2022-23\n",
    "\n",
    "This notebook has been provided as a template to get you started on the assignment.  Feel free to use it for your development, or do your development directly in Python.\n",
    "\n",
    "You can find a full description of the assignment [here](http://www.inf.ed.ac.uk/teaching/courses/asr/2022-23/coursework.pdf).\n",
    "\n",
    "You are provided with two Python modules `observation_model.py` and `wer.py`.  The first was described in [Lab 3](https://github.com/ZhaoZeyu1995/asr_labs/blob/master/asr_lab3_4.ipynb).  The second can be used to compute the number of substitution, deletion and insertion errors between ASR output and a reference text.\n",
    "\n",
    "It can be used as follows:\n",
    "\n",
    "```python\n",
    "import wer\n",
    "\n",
    "my_refence = 'A B C'\n",
    "my_output = 'A C C D'\n",
    "\n",
    "wer.compute_alignment_errors(my_reference, my_output)\n",
    "```\n",
    "\n",
    "This produces a tuple $(s,d,i)$ giving counts of substitution,\n",
    "deletion and insertion errors respectively - in this example (1, 0, 1).  The function accepts either two strings, as in the example above, or two lists.  Matching is case sensitive.\n",
    "\n",
    "## Template code\n",
    "\n",
    "Assuming that you have already made a function to generate an WFST, `create_wfst()` and a decoder class, `MyViterbiDecoder`, you can perform recognition on all the audio files as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import observation_model\n",
    "import math\n",
    "import openfst_python as fst\n",
    "\n",
    "from subprocess import check_call\n",
    "from IPython.display import Image\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import wer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "        self.forward = 0\n",
    "\n",
    "        \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []   # stores likelihood along best path reaching state j\n",
    "        self.B = []   # stores identity of best previous state reaching state j\n",
    "        self.W = []   # stores output labels sequence along arc reaching j - this removes need for \n",
    "                      # extra code to read the output sequence along the best path\n",
    "        \n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "            self.B.append([-1]*self.f.num_states())\n",
    "            self.W.append([[] for i in range(self.f.num_states())])  #  multiplying the empty list doesn't make multiple\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.V[0][self.f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)        \n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(self.f.states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if self.V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in self.f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if self.V[t][j] > self.V[t][i] + float(arc.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.V[t][j] = self.V[t][i] + float(arc.weight)\n",
    "                        \n",
    "                        # save backtrace information.  In the case of an epsilon transition, \n",
    "                        # we save the identity of the best state at t-1.  This means we may not\n",
    "                        # be able to fully recover the best path, but to do otherwise would\n",
    "                        # require a more complicated way of storing backtrace information\n",
    "                        self.B[t][j] = self.B[t][i] \n",
    "                        \n",
    "                        # and save the output labels encountered - this is a list, because\n",
    "                        # there could be multiple output labels (in the case of <eps> arcs)\n",
    "                        if arc.olabel != 0:\n",
    "                            self.W[t][j] = self.W[t][i] + [arc.olabel]\n",
    "                        else:\n",
    "                            self.W[t][j] = self.W[t][i]\n",
    "                        \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "          \n",
    "        for i in self.f.states():\n",
    "            \n",
    "            if not self.V[t-1][i] == self.NLL_ZERO:   # no point in propagating states with zero probability\n",
    "                \n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0: # <eps> transitions don't emit an observation\n",
    "                        j = arc.nextstate\n",
    "                        tp = float(arc.weight)  # transition prob\n",
    "                        ep = -self.om.log_observation_probability(self.f.input_symbols().find(arc.ilabel), t)  # emission negative log prob\n",
    "                        self.forward +=1\n",
    "                        prob = tp + ep + self.V[t-1][i] # they're logs\n",
    "                        if prob < self.V[t][j]:\n",
    "                            self.V[t][j] = prob\n",
    "                            self.B[t][j] = i\n",
    "                            \n",
    "                            # store the output labels encountered too\n",
    "                            if arc.olabel !=0:\n",
    "                                self.W[t][j] = [arc.olabel]\n",
    "                            else:\n",
    "                                self.W[t][j] = []\n",
    "                            \n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \"\"\" this incorporates the probability of terminating at each state\n",
    "        \"\"\"\n",
    "        \n",
    "        for state in self.f.states():\n",
    "            final_weight = float(self.f.final(state))\n",
    "            if self.V[-1][state] != self.NLL_ZERO:\n",
    "                if final_weight == math.inf:\n",
    "                    self.V[-1][state] = self.NLL_ZERO  # effectively says that we can't end in this state\n",
    "                else:\n",
    "                    self.V[-1][state] += final_weight\n",
    "                    \n",
    "        # get a list of all states where there was a path ending with non-zero probability\n",
    "        finished = [x for x in self.V[-1] if x < self.NLL_ZERO]\n",
    "        if not finished:  # if empty\n",
    "            print(\"No path got to the end of the observations.\")\n",
    "        \n",
    "        \n",
    "    def decode(self):\n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            self.traverse_epsilon_arcs(t)\n",
    "            t += 1\n",
    "        self.finalise_decoding()\n",
    "        \n",
    "        return self.forward\n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        best_final_state = self.V[-1].index(min(self.V[-1])) # argmin\n",
    "        best_state_sequence = [best_final_state]\n",
    "        best_out_sequence = []\n",
    "        \n",
    "        t = self.om.observation_length()   # ie T\n",
    "        j = best_final_state\n",
    "        \n",
    "        while t >= 0:\n",
    "            i = self.B[t][j]\n",
    "            best_state_sequence.append(i)\n",
    "            best_out_sequence = self.W[t][j] + best_out_sequence  # computer scientists might like\n",
    "                                                                                # to make this more efficient!\n",
    "\n",
    "            # continue the backtrace at state i, time t-1\n",
    "            j = i  \n",
    "            t-=1\n",
    "            \n",
    "        best_state_sequence.reverse()\n",
    "        \n",
    "        # convert the best output sequence from FST integer labels into strings\n",
    "        best_out_sequence = ' '.join([ self.f.output_symbols().find(label) for label in best_out_sequence])\n",
    "        \n",
    "        return (best_state_sequence, best_out_sequence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wfst(f):\n",
    "    f.draw('tmp.dot', portrait=True)\n",
    "    check_call(['dot','-Tpng','-Gdpi=500','tmp.dot','-o','tmp.png'])\n",
    "    Image(filename='tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lexicon(lex_file):\n",
    "    \"\"\"\n",
    "    Parse the lexicon file and return it in dictionary form.\n",
    "    \n",
    "    Args:\n",
    "        lex_file (str): filename of lexicon file with structure '<word> <phone1> <phone2>...'\n",
    "                        eg. peppers p eh p er z\n",
    "\n",
    "    Returns:\n",
    "        lex (dict): dictionary mapping words to list of phones\n",
    "    \"\"\"\n",
    "    \n",
    "    lex = {}  # create a dictionary for the lexicon entries (this could be a problem with larger lexica)\n",
    "    with open(lex_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.split()  # split at each space\n",
    "            if line[0] in lex.keys():\n",
    "                lex[line[0] + \"_\"] = line[1:] \n",
    "            else:\n",
    "                lex[line[0]] = line[1:]  # first field the word, the rest is the phones\n",
    "    return lex\n",
    "\n",
    "def generate_symbol_tables(lexicon, n=3):\n",
    "    '''\n",
    "    Return word, phone and state symbol tables based on the supplied lexicon\n",
    "        \n",
    "    Args:\n",
    "        lexicon (dict): lexicon to use, created from the parse_lexicon() function\n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        word_table (fst.SymbolTable): table of words\n",
    "        phone_table (fst.SymbolTable): table of phones\n",
    "        state_table (fst.SymbolTable): table of HMM phone-state IDs\n",
    "    '''\n",
    "    \n",
    "    state_table = fst.SymbolTable()\n",
    "    phone_table = fst.SymbolTable()\n",
    "    word_table = fst.SymbolTable()\n",
    "    \n",
    "    # add empty <eps> symbol to all tables\n",
    "    state_table.add_symbol('<eps>')\n",
    "    phone_table.add_symbol('<eps>')\n",
    "    word_table.add_symbol('<eps>')\n",
    "    \n",
    "    for word, phones  in lexicon.items():\n",
    "        \n",
    "        word_table.add_symbol(word)\n",
    "        \n",
    "        for p in phones: # for each phone\n",
    "            \n",
    "            phone_table.add_symbol(p)\n",
    "            for i in range(1,n+1): # for each state 1 to n\n",
    "                state_table.add_symbol('{}_{}'.format(p, i))\n",
    "            \n",
    "    return word_table, phone_table, state_table\n",
    "\n",
    "\n",
    "# call these two functions\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "\n",
    "def generate_phone_wfst(f, start_state, phone, n, loop_w, next_w ):\n",
    "    \"\"\"\n",
    "    Generate a WFST representating an n-state left-to-right phone HMM\n",
    "    \n",
    "    Args:\n",
    "        f (fst.Fst()): an FST object, assumed to exist already\n",
    "        start_state (int): the index of the first state, assmed to exist already\n",
    "        phone (str): the phone label \n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        the final state of the FST\n",
    "    \"\"\"\n",
    "    \n",
    "    current_state = start_state\n",
    "    sl_weight = fst.Weight('log', -math.log(loop_w))  # weight for self-loop\n",
    "    next_weight = fst.Weight('log', -math.log(next_w)) # weight to next state\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        in_label = state_table.find('{}_{}'.format(phone, i))\n",
    "        \n",
    "        # self-loop back to current state\n",
    "        f.add_arc(current_state, fst.Arc(in_label, 0, sl_weight, current_state))\n",
    "        \n",
    "        # transition to next state\n",
    "        \n",
    "        # we want to output the phone label on the final state\n",
    "        # note: if outputting words instead this code should be modified\n",
    "        if i == n:\n",
    "            out_label = phone_table.find(phone)\n",
    "        else:\n",
    "            out_label = 0   # output empty <eps> label\n",
    "            \n",
    "        next_state = f.add_state()\n",
    "        f.add_arc(current_state, fst.Arc(in_label, 0, next_weight, next_state))    # changed to 0 ! \n",
    "       \n",
    "        current_state = next_state\n",
    "        \n",
    "    return current_state\n",
    "\n",
    "def generate_word_wfst(word):\n",
    "    \"\"\" Generate a WFST for any word in the lexicon, composed of 3-state phone WFSTs.\n",
    "        This will currently output word labels.  \n",
    "        Exercise: could you modify this function and the one above to output a single phone label instead?\n",
    "    \n",
    "    Args:\n",
    "        word (str): the word to generate\n",
    "        \n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    f = fst.Fst('log')\n",
    "    \n",
    "    # create the start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    current_state = start_state\n",
    "    \n",
    "    # iterate over all the phones in the word\n",
    "    for (i,phone) in enumerate(lex[word]):   # will raise an exception if word is not in the lexicon\n",
    "        \n",
    "        current_state = generate_phone_wfst(f, current_state, phone, 3)\n",
    "    \n",
    "        if i == len(lex[word]) - 1:\n",
    "            next_state = f.add_state()\n",
    "            f.add_arc(current_state, fst.Arc(in_label, word_table.find(word), certain_weight, current_state))\n",
    "            \n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "        \n",
    "    f.set_final(current_state)\n",
    "    \n",
    "    return f\n",
    "\n",
    "def generate_word_sequence_recognition_wfst(n, probs, loop_w, next_w):\n",
    "    \"\"\" generate a HMM to recognise any single word sequence for words in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "\n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    \n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    #reduced_weight = fst.Weight('log', -math.log(1/(5*len(lex))))\n",
    "    \n",
    "    #this one used before\n",
    "    next_weight = fst.Weight('log', -math.log(0.1))\n",
    "    #next_weight = fst.Weight('log', 0)\n",
    "    #testing this one \n",
    "    \n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    #f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(0.3)), start_state))\n",
    "    \n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "\n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(probs[word])), current_state))\n",
    "        \n",
    "        for (i, phone) in enumerate(phones): \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n, loop_w , next_w)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "            if i == len(lex[word]) - 1:\n",
    "\n",
    "                next_state = f.add_state()\n",
    "                f.add_arc(current_state, fst.Arc(0, word_table.find(word.replace(\"_\", \"\")), certain_weight, next_state))\n",
    "                current_state= next_state\n",
    "                \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, next_weight, start_state))\n",
    "        \n",
    "    return f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wfst(n, state_table, phone_table, word_probabilities, loop_w = 0.3, next_w = 0.7):\n",
    "    # word probabilities: a dictionary, to adjust weights. \n",
    "    f = generate_word_sequence_recognition_wfst(n, word_probabilities, loop_w, next_w)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(word_table)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_dict = {}\n",
    "for word, _ in lex.items():\n",
    "    even_dict[word] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all for different combinations of the self-loop / next state weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "f = create_wfst(3, state_table, phone_table, even_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 327 µs, sys: 502 µs, total: 829 µs\n",
      "Wall time: 836 µs\n",
      "the of pickled piper the of peter the\n",
      "a pickled piper of peter\n",
      "(1, 0, 3) 5\n",
      "CPU times: user 720 µs, sys: 0 ns, total: 720 µs\n",
      "Wall time: 727 µs\n",
      "the where's peter the\n",
      "where's peter\n",
      "(0, 0, 2) 2\n",
      "CPU times: user 149 µs, sys: 116 µs, total: 265 µs\n",
      "Wall time: 269 µs\n",
      "CPU times: user 0 ns, sys: 478 µs, total: 478 µs\n",
      "Wall time: 484 µs\n",
      "CPU times: user 606 µs, sys: 297 µs, total: 903 µs\n",
      "Wall time: 910 µs\n",
      "CPU times: user 1.11 ms, sys: 405 µs, total: 1.52 ms\n",
      "Wall time: 1.53 ms\n",
      "CPU times: user 226 µs, sys: 70 µs, total: 296 µs\n",
      "Wall time: 300 µs\n",
      "CPU times: user 594 µs, sys: 159 µs, total: 753 µs\n",
      "Wall time: 760 µs\n",
      "CPU times: user 324 µs, sys: 77 µs, total: 401 µs\n",
      "Wall time: 404 µs\n",
      "2080 318 2434 35321580\n"
     ]
    }
   ],
   "source": [
    "\n",
    "utterance_c = 0\n",
    "word_c = 0\n",
    "errors_sum = 0\n",
    "fr = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "        #if utterance_c < 6:                                                            # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "        fr += decoder.decode()\n",
    "        if utterance_c < 10:\n",
    "            %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        else:\n",
    "            (state_path, words) = decoder.backtrace()\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 3:\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "            print(error_counts, word_count) # you'll need to accumulate these\n",
    "        errors_sum += sum(error_counts)\n",
    "        word_c += word_count\n",
    "print(errors_sum, utterance_c, word_c, fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_c = 0\n",
    "# word_c = 0\n",
    "# word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "# f = create_wfst(3, state_table, phone_table, even_dict, 0.7, 0.3)\n",
    "# errors_sum = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                          # audio files\n",
    "#         utterance_c+=1\n",
    "#         decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "#         decoder.decode()\n",
    "#         if utterance_c < 10:\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "#         if utterance_c < 3:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         word_c += word_count\n",
    "# print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_c = 0\n",
    "# word_c = 0\n",
    "# word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "# f = create_wfst(3, state_table, phone_table, even_dict, 0.5, 0.5)\n",
    "# errors_sum = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#                                                                     # audio files\n",
    "#         utterance_c+=1\n",
    "#         decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "#         decoder.decode()\n",
    "#         if utterance_c < 10:\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "#         if utterance_c < 3:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         word_c += word_count\n",
    "# print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_c = 0\n",
    "# word_c = 0\n",
    "# word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "# f = create_wfst(3, state_table, phone_table, even_dict, 0.9, 0.1)\n",
    "# errors_sum = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#                                                                     # audio files\n",
    "#         utterance_c+=1\n",
    "#         decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "#         decoder.decode()\n",
    "#         if utterance_c < 10:\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "#         if utterance_c < 3:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         word_c += word_count\n",
    "# print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_c = 0\n",
    "# word_c = 0\n",
    "# word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "# f = create_wfst(3, state_table, phone_table, even_dict, 0.9, 0.1)\n",
    "# errors_sum = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#     if utterance_c < 10:\n",
    "#         utterance_c+=1\n",
    "#         decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "#         %time decoder.decode()\n",
    "#         (state_path, words) = decoder.backtrace()\n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "#         if utterance_c < 3:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         word_c += word_count\n",
    "# print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_c = 0\n",
    "# word_c = 0\n",
    "# word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "# f = create_wfst(3, state_table, phone_table, even_dict, 0.9, 0.1)\n",
    "# errors_sum = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#                                                                     # audio files\n",
    "#         utterance_c+=1\n",
    "#         decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "#         decoder.decode()\n",
    "#         if utterance_c < 10:\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "#         if utterance_c < 3:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         word_c += word_count\n",
    "# print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_c = 0\n",
    "# word_c = 0\n",
    "# word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "# f = create_wfst(3, state_table, phone_table, even_dict, 0.1, 0.9)\n",
    "# errors_sum = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#                                                                     # audio files\n",
    "#         utterance_c+=1\n",
    "#         decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "        \n",
    "#         decoder.decode()\n",
    "#         if utterance_c < 10:\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "#         if utterance_c < 3:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         word_c += word_count\n",
    "# print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of states for assesing memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(f.states()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 1\n",
    "# for word, phones in lex.items():\n",
    "#         a += 3*len(phones) + 2\n",
    "# a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wfst with unigram probabilities based on counts, instead of even probabilities for all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.05834018077239113,\n",
       " 'of': 0.10230073952341824,\n",
       " 'peck': 0.11133935907970419,\n",
       " 'peppers': 0.13475760065735415,\n",
       " 'peter': 0.12900575184880855,\n",
       " 'picked': 0.11298274445357437,\n",
       " 'pickled': 0.11750205423171733,\n",
       " 'piper': 0.11503697617091208,\n",
       " 'the': 0.06409202958093672,\n",
       " \"where's\": 0.05464256368118324,\n",
       " 'SUM': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = {}\n",
    "for word in lex.keys():\n",
    "    c[word] = 0\n",
    "c[\"SUM\"] = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):\n",
    "    transcript=read_transcription(wav_file)\n",
    "    for word in lex.keys():\n",
    "        count = transcript.count(word)\n",
    "        c[word] += count\n",
    "        c[\"SUM\"] += count\n",
    "        \n",
    "        \n",
    "unigram_probs = {}\n",
    "for w, count in c.items():\n",
    "    if \"_\" not in w:\n",
    "        unigram_probs[w] = count /c[\"SUM\"]\n",
    "        \n",
    "unigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_sequence_recognition_wfst_unigram(n, probs):\n",
    "    \"\"\" generate a HMM to recognise any single word sequence for words in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "\n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    \n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    #reduced_weight = fst.Weight('log', -math.log(1/(5*len(lex))))\n",
    "    next_weight = fst.Weight('log', -math.log(0.05))\n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    #f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(0.3)), start_state))\n",
    "    \n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "\n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(probs[w])), current_state))\n",
    "        \n",
    "        for (i, phone) in enumerate(phones): \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n, 0.9, 0.1)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "            if i == len(lex[word]) - 1:\n",
    "\n",
    "                next_state = f.add_state()\n",
    "                f.add_arc(current_state, fst.Arc(0, word_table.find(word.replace(\"_\", \"\")), certain_weight, next_state))\n",
    "                current_state= next_state\n",
    "                \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, next_weight, start_state))\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "def create_wfst_unigram(n, state_table, phone_table, word_probabilities):\n",
    "    # word probabilities: a dictionary, to adjust weights. \n",
    "    f = generate_word_sequence_recognition_wfst_unigram(n, word_probabilities)\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(word_table)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utterance_c = 0\n",
    "# word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "# f = create_wfst_unigram(3, state_table, phone_table, unigram_probs)\n",
    "# errors_sum = 0\n",
    "# word_c = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#                                                                    # audio files\n",
    "#         utterance_c+=1\n",
    "#         decoder = MyViterbiDecoder(f, wav_file)\n",
    "    \n",
    "#         decoder.decode()\n",
    "#         if utterance_c < 10:\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             (state_path, words) = decoder.backtrace() \n",
    "        \n",
    "#         transcription = read_transcription(wav_file)                                    \n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "    \n",
    "#         if utterance_c < 3:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         word_c += word_count\n",
    "\n",
    "# print(errors_sum, utterance_c, word_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding silence states at the start and between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_table.add_symbol(\"sil_1\")\n",
    "state_table.add_symbol(\"sil_2\")\n",
    "state_table.add_symbol(\"sil_3\")\n",
    "state_table.add_symbol(\"sil_4\")\n",
    "state_table.add_symbol(\"sil_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sil_wfst(n, word_probabilities, sil_prob = 0.1, ergodic = False):\n",
    "    \"\"\" generate a HMM to recognise any single word sequence for words in the lexicon\n",
    "    \n",
    "    Args:\n",
    "        n (int): states per phone HMM\n",
    "\n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    f = fst.Fst('log')\n",
    "\n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    \n",
    "    #even_weight = fst.Weight('log', -math.log(1/len(lex)))\n",
    "    #reduced_weight = fst.Weight('log', -math.log(1/(5*len(lex))))\n",
    "    next_weight = fst.Weight('log', -math.log(0.1))\n",
    "    certain_weight =  fst.Weight('log', -math.log(1))\n",
    "    \n",
    "    # create a single start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    #first_silent = f.add_state()\n",
    "    #last_silent = f.add_state()\n",
    "    #f.set_final(last_silent)\n",
    "    \n",
    "    if ergodic == True:\n",
    "        sil_states = [0, 0, 0, 0, 0]\n",
    "        for i in range(5):\n",
    "            sil_states[i] = f.add_state()\n",
    "        #start to first\n",
    "        #f.add_arc(start_state, fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', -math.log(sil_prob)),sil_states[0]))\n",
    "        f.add_arc(start_state, fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', -math.log(sil_prob)),sil_states[0]))\n",
    "        #loop for sil 1\n",
    "        f.add_arc(sil_states[0], fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', -math.log(0.9)),sil_states[0]))\n",
    "        #loop for sil 5\n",
    "        f.add_arc(sil_states[4], fst.Arc(state_table.find(\"sil_5\"), 0, fst.Weight('log', -math.log(0.9)),sil_states[4]))\n",
    "        #sil 5 to start state\n",
    "        f.add_arc(sil_states[4], fst.Arc(0, 0, next_weight, start_state))\n",
    "        f.set_final(sil_states[4])\n",
    "    \n",
    "        for i in [1,2,3]:\n",
    "            #loop\n",
    "            f.add_arc(sil_states[i], fst.Arc(state_table.find(\"sil_\" + str(i+1)), 0, fst.Weight('log', -math.log(0.9)),sil_states[i]))\n",
    "            #to final\n",
    "            f.add_arc(sil_states[i], fst.Arc(state_table.find(\"sil_\" + str(i+1)), 0, fst.Weight('log', -math.log(0.1)),sil_states[4]))\n",
    "            #from first\n",
    "            f.add_arc(sil_states[0], fst.Arc(state_table.find(\"sil_\" + str(i+1)), 0, fst.Weight('log', -math.log(0.1)),sil_states[i]))\n",
    "        \n",
    "            for j in [1,2,3]:\n",
    "                if i != j:\n",
    "                    f.add_arc(sil_states[i], fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', -math.log(0.1)),sil_states[j]))\n",
    "\n",
    "    else:\n",
    "        sil_states = [0, 0, 0, 0, 0]\n",
    "        for i in range(5):\n",
    "            sil_states[i] = f.add_state()\n",
    "        # leftto right\n",
    "        #start to first\n",
    "        f.add_arc(start_state, fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', -math.log(sil_prob)),sil_states[0]))\n",
    "        #f.add_arc(start_state, fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', 3),sil_states[0]))\n",
    "        #loop for sil 1\n",
    "        #f.add_arc(sil_states[0], fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', -math.log(0.1)),sil_states[0]))\n",
    "        #loop for sil 5\n",
    "        f.add_arc(sil_states[4], fst.Arc(state_table.find(\"sil_5\"), 0, fst.Weight('log', -math.log(0.9)),sil_states[4]))\n",
    "        #sil 5 to start state\n",
    "        f.add_arc(sil_states[4], fst.Arc(0, 0, next_weight, start_state))\n",
    "        f.set_final(sil_states[4])\n",
    "\n",
    "        for j in [0, 1,2,3]:\n",
    "            #loop\n",
    "            f.add_arc(sil_states[j], fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', 0.9),sil_states[j]))\n",
    "            #next\n",
    "            f.add_arc(sil_states[j], fst.Arc(state_table.find(\"sil_1\"), 0, fst.Weight('log', 0.1),sil_states[j+1]))\n",
    "        \n",
    "    for word, phones in lex.items():\n",
    "        current_state = f.add_state()\n",
    "        \n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight('log', -math.log(word_probabilities[word])), current_state))\n",
    "        \n",
    "        for (i, phone) in enumerate(phones): \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, n, 0.9, 0.1)\n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "            if i == len(lex[word]) - 1:\n",
    "\n",
    "                next_state = f.add_state()\n",
    "                f.add_arc(current_state, fst.Arc(0, word_table.find(word.replace(\"_\", \"\")), certain_weight, next_state))\n",
    "                current_state= next_state\n",
    "                \n",
    "        f.set_final(current_state)\n",
    "        f.add_arc(current_state, fst.Arc(0, 0, next_weight, start_state))\n",
    "        \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = generate_sil_wfst(3, even_dict, 0.1, ergodic = True)\n",
    "s.set_input_symbols(state_table)\n",
    "s.set_output_symbols(word_table)\n",
    "show_wfst(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = generate_sil_wfst(3, even_dict, 0.1)\n",
    "# s.set_input_symbols(state_table)\n",
    "# s.set_output_symbols(word_table)\n",
    "\n",
    "# errors_sum = 0\n",
    "# utterances = 0\n",
    "# words_no = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#         #if utterances < 10:                                                                       # audio files\n",
    "#         utterances += 1\n",
    "#         decoder = MyViterbiDecoder(s, wav_file)\n",
    "    \n",
    "#         if utterances < 10:\n",
    "#             %time decoder.decode()\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             decoder.decode()\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "            \n",
    "            \n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "    \n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "    \n",
    "#         if sum(error_counts) > 10:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) \n",
    "#             print(utterances)\n",
    "#             # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         words_no += word_count\n",
    "# print(errors_sum, utterances, words_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = generate_sil_wfst(3, even_dict, 0.1, ergodic = True)\n",
    "# s.set_input_symbols(state_table)\n",
    "# s.set_output_symbols(word_table)\n",
    "\n",
    "# errors_sum = 0\n",
    "# utterances = 0\n",
    "# words_no = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#         #if utterances < 10:                                                                       # audio files\n",
    "#         utterances += 1\n",
    "#         decoder = MyViterbiDecoder(s, wav_file)\n",
    "    \n",
    "#         if utterances < 10:\n",
    "#             %time decoder.decode()\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             decoder.decode()\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "            \n",
    "            \n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "    \n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "    \n",
    "#         if sum(error_counts) > 10:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) \n",
    "#             print(utterances)\n",
    "#             # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         words_no += word_count\n",
    "# print(errors_sum, utterances, words_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = generate_sil_wfst(3, even_dict, 0.05)\n",
    "# s.set_input_symbols(state_table)\n",
    "# s.set_output_symbols(word_table)\n",
    "\n",
    "# errors_sum = 0\n",
    "# utterances = 0\n",
    "# words_no = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                 # audio files\n",
    "#         utterances += 1\n",
    "#         decoder = MyViterbiDecoder(s, wav_file)\n",
    "    \n",
    "#         if utterances < 10:\n",
    "#             %time decoder.decode()\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             decoder.decode()\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "            \n",
    "            \n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "    \n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "    \n",
    "#         if utterances < 4:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count)     # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         words_no += word_count\n",
    "# print(errors_sum, utterances, words_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = generate_sil_wfst(3, even_dict, 0.1)\n",
    "# s.set_input_symbols(state_table)\n",
    "# s.set_output_symbols(word_table)\n",
    "\n",
    "# errors_sum = 0\n",
    "# utterances = 0\n",
    "# words_no = 0\n",
    "# for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own\n",
    "#         #if utterances < 10:                                                                       # audio files\n",
    "#         utterances += 1\n",
    "#         decoder = MyViterbiDecoder(s, wav_file)\n",
    "    \n",
    "#         if utterances < 10:\n",
    "#             %time decoder.decode()\n",
    "#             %time (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "#         else:\n",
    "#             decoder.decode()\n",
    "#             (state_path, words) = decoder.backtrace()\n",
    "            \n",
    "            \n",
    "#         transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "\n",
    "    \n",
    "#         error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "#         word_count = len(transcription.split())\n",
    "    \n",
    "#         if sum(error_counts) > 2:\n",
    "#             print (words)\n",
    "#             print(transcription)\n",
    "#             print(error_counts, word_count) \n",
    "#             print(utterances)\n",
    "#             # you'll need to accumulate these\n",
    "#         errors_sum += sum(error_counts)\n",
    "#         words_no += word_count\n",
    "# print(errors_sum, utterances, words_no)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name, pruning_threshold = 500):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "        self.threshold = pruning_threshold\n",
    "        self.skipped = 0\n",
    "        self.forward = 0\n",
    "\n",
    "        \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []   # stores likelihood along best path reaching state j\n",
    "        self.B = []   # stores identity of best previous state reaching state j\n",
    "        self.W = []   # stores output labels sequence along arc reaching j - this removes need for \n",
    "                      # extra code to read the output sequence along the best path\n",
    "        \n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "            self.B.append([-1]*self.f.num_states())\n",
    "            self.W.append([[] for i in range(self.f.num_states())])  #  multiplying the empty list doesn't make multiple\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.V[0][self.f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)        \n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(self.f.states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if self.V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in self.f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if self.V[t][j] > self.V[t][i] + float(arc.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.V[t][j] = self.V[t][i] + float(arc.weight)\n",
    "                        \n",
    "                        # save backtrace information.  In the case of an epsilon transition, \n",
    "                        # we save the identity of the best state at t-1.  This means we may not\n",
    "                        # be able to fully recover the best path, but to do otherwise would\n",
    "                        # require a more complicated way of storing backtrace information\n",
    "                        self.B[t][j] = self.B[t][i] \n",
    "                        \n",
    "                        # and save the output labels encountered - this is a list, because\n",
    "                        # there could be multiple output labels (in the case of <eps> arcs)\n",
    "                        if arc.olabel != 0:\n",
    "                            self.W[t][j] = self.W[t][i] + [arc.olabel]\n",
    "                        else:\n",
    "                            self.W[t][j] = self.W[t][i]\n",
    "                        \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "        #find the best V[t-1]\n",
    "        best = max(2.3, min(self.V[t-1]))\n",
    "        for i in self.f.states():\n",
    "            \n",
    "            #if not self.V[t-1][i] == self.NLL_ZERO:   # no point in propagating states with zero probability\n",
    "            if (self.V[t-1][i] < best * self.threshold):   # bigger value means lower probability ! \n",
    "                #print(self.V[t-1][i])\n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0: # <eps> transitions don't emit an observation\n",
    "                        j = arc.nextstate\n",
    "                        tp = float(arc.weight)  # transition prob\n",
    "                        ep = -self.om.log_observation_probability(self.f.input_symbols().find(arc.ilabel), t)  # emission negative log prob\n",
    "                        self.forward +=1\n",
    "                        prob = tp + ep + self.V[t-1][i] # they're logs\n",
    "                        if prob < self.V[t][j]:\n",
    "                            self.V[t][j] = prob\n",
    "                            self.B[t][j] = i\n",
    "                            \n",
    "                            # store the output labels encountered too\n",
    "                            if arc.olabel !=0:\n",
    "                                self.W[t][j] = [arc.olabel]\n",
    "                            else:\n",
    "                                self.W[t][j] = []\n",
    "            else:\n",
    "                self.skipped += 1\n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \"\"\" this incorporates the probability of terminating at each state\n",
    "        \"\"\"\n",
    "        \n",
    "        for state in self.f.states():\n",
    "            final_weight = float(self.f.final(state))\n",
    "            if self.V[-1][state] != self.NLL_ZERO:\n",
    "                if final_weight == math.inf:\n",
    "                    self.V[-1][state] = self.NLL_ZERO  # effectively says that we can't end in this state\n",
    "                else:\n",
    "                    self.V[-1][state] += final_weight\n",
    "                    \n",
    "        # get a list of all states where there was a path ending with non-zero probability\n",
    "        finished = [x for x in self.V[-1] if x < self.NLL_ZERO]\n",
    "        if not finished:  # if empty\n",
    "            print(\"No path got to the end of the observations.\")\n",
    "        \n",
    "        \n",
    "    def decode(self):\n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            self.traverse_epsilon_arcs(t)\n",
    "            t += 1\n",
    "        self.finalise_decoding()\n",
    "        \n",
    "        return self.forward\n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        best_final_state = self.V[-1].index(min(self.V[-1])) # argmin\n",
    "        best_state_sequence = [best_final_state]\n",
    "        best_out_sequence = []\n",
    "        \n",
    "        t = self.om.observation_length()   # ie T\n",
    "        j = best_final_state\n",
    "        \n",
    "        while t >= 0:\n",
    "            i = self.B[t][j]\n",
    "            best_state_sequence.append(i)\n",
    "            best_out_sequence = self.W[t][j] + best_out_sequence  # computer scientists might like\n",
    "                                                                                # to make this more efficient!\n",
    "\n",
    "            # continue the backtrace at state i, time t-1\n",
    "            j = i  \n",
    "            t-=1\n",
    "            \n",
    "        best_state_sequence.reverse()\n",
    "        \n",
    "        # convert the best output sequence from FST integer labels into strings\n",
    "        best_out_sequence = ' '.join([ self.f.output_symbols().find(label) for label in best_out_sequence])\n",
    "        \n",
    "        return (best_state_sequence, best_out_sequence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 0 ns, total: 2.63 s\n",
      "Wall time: 2.63 s\n",
      "(1, 0, 2) 5\n",
      "the of pickled piper of peter the\n",
      "a pickled piper of peter\n",
      "CPU times: user 1.8 s, sys: 0 ns, total: 1.8 s\n",
      "Wall time: 1.8 s\n",
      "(0, 0, 2) 2\n",
      "the where's peter the\n",
      "where's peter\n",
      "CPU times: user 2.18 s, sys: 3 µs, total: 2.18 s\n",
      "Wall time: 2.18 s\n",
      "(0, 1, 2) 4\n",
      "the peter picked peck the\n",
      "peter picked a peck\n",
      "CPU times: user 2.26 s, sys: 0 ns, total: 2.26 s\n",
      "Wall time: 2.26 s\n",
      "(0, 0, 2) 3\n",
      "the where's the peppers the\n",
      "where's the peppers\n",
      "CPU times: user 2.52 s, sys: 0 ns, total: 2.52 s\n",
      "Wall time: 2.52 s\n",
      "CPU times: user 4.62 s, sys: 0 ns, total: 4.62 s\n",
      "Wall time: 4.62 s\n",
      "CPU times: user 2.85 s, sys: 10 µs, total: 2.85 s\n",
      "Wall time: 2.85 s\n",
      "CPU times: user 3.39 s, sys: 0 ns, total: 3.39 s\n",
      "Wall time: 3.39 s\n",
      "CPU times: user 3.35 s, sys: 2 µs, total: 3.35 s\n",
      "Wall time: 3.35 s\n",
      "1609 318 2434 35216562\n"
     ]
    }
   ],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict, 0.9, 0.1 )\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "s = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =1.5)\n",
    "    \n",
    "        if utterance_c < 10:\n",
    "            %time s += decoder.decode()\n",
    "        else:\n",
    "                s += decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5:\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 16 ms, total: 2.73 s\n",
      "Wall time: 2.71 s\n",
      "(1, 0, 2) 5\n",
      "the of pickled piper of peter the\n",
      "a pickled piper of peter\n",
      "CPU times: user 1.79 s, sys: 3 µs, total: 1.79 s\n",
      "Wall time: 1.79 s\n",
      "(0, 0, 2) 2\n",
      "the where's peter the\n",
      "where's peter\n",
      "CPU times: user 2.19 s, sys: 0 ns, total: 2.19 s\n",
      "Wall time: 2.19 s\n",
      "(0, 1, 2) 4\n",
      "the peter picked peck the\n",
      "peter picked a peck\n",
      "CPU times: user 2.23 s, sys: 0 ns, total: 2.23 s\n",
      "Wall time: 2.23 s\n",
      "(0, 0, 2) 3\n",
      "the where's the peppers the\n",
      "where's the peppers\n",
      "CPU times: user 2.47 s, sys: 0 ns, total: 2.47 s\n",
      "Wall time: 2.47 s\n",
      "CPU times: user 4.59 s, sys: 0 ns, total: 4.59 s\n",
      "Wall time: 4.6 s\n",
      "CPU times: user 2.9 s, sys: 8 µs, total: 2.9 s\n",
      "Wall time: 2.9 s\n",
      "CPU times: user 3.41 s, sys: 3 µs, total: 3.41 s\n",
      "Wall time: 3.41 s\n",
      "CPU times: user 3.37 s, sys: 0 ns, total: 3.37 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict, 0.9, 0.1 )\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "s = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =1.25)\n",
    "    \n",
    "        if utterance_c < 10:\n",
    "            %time s += decoder.decode()\n",
    "        else:\n",
    "                s += decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5:\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.38 s, sys: 28 ms, total: 2.41 s\n",
      "Wall time: 2.38 s\n",
      "(1, 0, 2) 5\n",
      "the of pickled piper of peter the\n",
      "a pickled piper of peter\n",
      "CPU times: user 1.38 s, sys: 0 ns, total: 1.38 s\n",
      "Wall time: 1.38 s\n",
      "(0, 0, 2) 2\n",
      "the where's peter the\n",
      "where's peter\n",
      "CPU times: user 1.8 s, sys: 1e+03 ns, total: 1.8 s\n",
      "Wall time: 1.8 s\n",
      "(0, 1, 2) 4\n",
      "the peter picked peck the\n",
      "peter picked a peck\n",
      "CPU times: user 2.02 s, sys: 6 µs, total: 2.02 s\n",
      "Wall time: 2.03 s\n",
      "(0, 0, 2) 3\n",
      "the where's the peppers the\n",
      "where's the peppers\n",
      "CPU times: user 2.14 s, sys: 8 µs, total: 2.14 s\n",
      "Wall time: 2.14 s\n",
      "CPU times: user 4.3 s, sys: 9 µs, total: 4.3 s\n",
      "Wall time: 4.3 s\n",
      "CPU times: user 2.54 s, sys: 0 ns, total: 2.54 s\n",
      "Wall time: 2.54 s\n",
      "CPU times: user 3.1 s, sys: 0 ns, total: 3.1 s\n",
      "Wall time: 3.1 s\n",
      "CPU times: user 2.93 s, sys: 0 ns, total: 2.93 s\n",
      "Wall time: 2.93 s\n",
      "1615 318 2434 31545944\n"
     ]
    }
   ],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict, 0.9, 0.1 )\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "s = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =1.1)\n",
    "    \n",
    "        if utterance_c < 10:\n",
    "            %time s += decoder.decode()\n",
    "        else:\n",
    "                s += decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5:\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 s, sys: 5 µs, total: 1.95 s\n",
      "Wall time: 1.95 s\n",
      "(1, 0, 3) 5\n",
      "where's the of pickled piper of peter the\n",
      "a pickled piper of peter\n",
      "CPU times: user 976 ms, sys: 0 ns, total: 976 ms\n",
      "Wall time: 976 ms\n",
      "(0, 0, 2) 2\n",
      "the where's peter the\n",
      "where's peter\n",
      "CPU times: user 1.3 s, sys: 3 µs, total: 1.3 s\n",
      "Wall time: 1.3 s\n",
      "(0, 1, 2) 4\n",
      "the peter picked peck the\n",
      "peter picked a peck\n",
      "CPU times: user 1.48 s, sys: 2 µs, total: 1.48 s\n",
      "Wall time: 1.49 s\n",
      "(0, 0, 2) 3\n",
      "the where's the peppers the\n",
      "where's the peppers\n",
      "CPU times: user 1.55 s, sys: 7 µs, total: 1.55 s\n",
      "Wall time: 1.55 s\n",
      "CPU times: user 3.84 s, sys: 0 ns, total: 3.84 s\n",
      "Wall time: 3.84 s\n",
      "CPU times: user 2.01 s, sys: 0 ns, total: 2.01 s\n",
      "Wall time: 2.01 s\n",
      "CPU times: user 2.47 s, sys: 0 ns, total: 2.47 s\n",
      "Wall time: 2.47 s\n",
      "CPU times: user 2.16 s, sys: 13 µs, total: 2.16 s\n",
      "Wall time: 2.16 s\n",
      "1637 318 2434 26240078\n"
     ]
    }
   ],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict, 0.9, 0.1 )\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "s = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =1.05)\n",
    "    \n",
    "        if utterance_c < 10:\n",
    "            %time s += decoder.decode()\n",
    "        else:\n",
    "                s += decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5:\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 s, sys: 4 µs, total: 1.71 s\n",
      "Wall time: 1.71 s\n",
      "(1, 0, 2) 5\n",
      "where's the pickled piper of peter the\n",
      "a pickled piper of peter\n",
      "CPU times: user 756 ms, sys: 1 µs, total: 756 ms\n",
      "Wall time: 756 ms\n",
      "(0, 0, 1) 2\n",
      "where's peter the\n",
      "where's peter\n",
      "CPU times: user 1.14 s, sys: 0 ns, total: 1.14 s\n",
      "Wall time: 1.14 s\n",
      "(1, 1, 1) 4\n",
      "where's picked peck the\n",
      "peter picked a peck\n",
      "CPU times: user 939 ms, sys: 3.88 ms, total: 943 ms\n",
      "Wall time: 943 ms\n",
      "(0, 0, 1) 3\n",
      "where's the peppers the\n",
      "where's the peppers\n",
      "CPU times: user 1.02 s, sys: 7 µs, total: 1.02 s\n",
      "Wall time: 1.02 s\n",
      "CPU times: user 2.65 s, sys: 0 ns, total: 2.65 s\n",
      "Wall time: 2.65 s\n",
      "CPU times: user 1.74 s, sys: 0 ns, total: 1.74 s\n",
      "Wall time: 1.74 s\n",
      "CPU times: user 2.25 s, sys: 0 ns, total: 2.25 s\n",
      "Wall time: 2.25 s\n",
      "CPU times: user 1.68 s, sys: 0 ns, total: 1.68 s\n",
      "Wall time: 1.68 s\n",
      "1633 318 2434 19060276\n"
     ]
    }
   ],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict, 0.9, 0.1 )\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "s = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =1.025)\n",
    "    \n",
    "        if utterance_c < 10:\n",
    "            %time s += decoder.decode()\n",
    "        else:\n",
    "                s += decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5:\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 470 ms, sys: 63.9 ms, total: 534 ms\n",
      "Wall time: 481 ms\n",
      "(1, 1, 1) 5\n",
      "where's piper of peter the\n",
      "a pickled piper of peter\n",
      "CPU times: user 203 ms, sys: 52 ms, total: 255 ms\n",
      "Wall time: 201 ms\n",
      "(0, 0, 1) 2\n",
      "where's peter the\n",
      "where's peter\n",
      "CPU times: user 358 ms, sys: 10 µs, total: 358 ms\n",
      "Wall time: 359 ms\n",
      "(1, 1, 1) 4\n",
      "where's picked peck the\n",
      "peter picked a peck\n",
      "CPU times: user 518 ms, sys: 0 ns, total: 518 ms\n",
      "Wall time: 518 ms\n",
      "(1, 0, 1) 3\n",
      "picked the peppers the\n",
      "where's the peppers\n",
      "CPU times: user 543 ms, sys: 3.99 ms, total: 547 ms\n",
      "Wall time: 547 ms\n",
      "CPU times: user 1.38 s, sys: 0 ns, total: 1.38 s\n",
      "Wall time: 1.38 s\n",
      "CPU times: user 641 ms, sys: 0 ns, total: 641 ms\n",
      "Wall time: 642 ms\n",
      "CPU times: user 804 ms, sys: 0 ns, total: 804 ms\n",
      "Wall time: 804 ms\n",
      "CPU times: user 796 ms, sys: 0 ns, total: 796 ms\n",
      "Wall time: 796 ms\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "No path got to the end of the observations.\n",
      "1805 318 2434 9042508\n"
     ]
    }
   ],
   "source": [
    "f = generate_word_sequence_recognition_wfst(3, even_dict, 0.9, 0.1 )\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(word_table)\n",
    "\n",
    "errors_sum = 0\n",
    "utterance_c = 0\n",
    "words_c = 0\n",
    "s = 0\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):    # replace path if using your own                                                                     # audio files\n",
    "        utterance_c+=1\n",
    "        decoder = PruningViterbiDecoder(f, wav_file, pruning_threshold =1.01)\n",
    "    \n",
    "        if utterance_c < 10:\n",
    "            %time s += decoder.decode()\n",
    "        else:\n",
    "                s += decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "        transcription = read_transcription(wav_file)                                           # to return the words along the best path\n",
    "       \n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        if utterance_c < 5:\n",
    "            print(error_counts, word_count)     # you'll need to accumulate these\n",
    "            print (words)\n",
    "            print(transcription)\n",
    "        errors_sum += sum(error_counts)\n",
    "        words_c += word_count\n",
    "        \n",
    "print(errors_sum, utterance_c, words_c, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
